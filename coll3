#-*-coding:utf-8-*-

import sys,os,shutil,re,time
import argparse
import ConfigParser 
from lib import *
from sql import *

from lxml.cssselect import CSSSelector
from lxml.etree import fromstring
import lxml.html
import HTMLParser

'''
python collect.py  -i 4 -t 1 -u "http://www.blog.com/index.php/blog/detail/8.html" 

python collect.py  -i 3 -t 1 -u "http://www.blog.com/index.php/blog/index.html?category=1&page=1"

'''


if __name__ == '__main__':
    param = [
      ['-i','--step',int,'this is step'],
      ['-t','--test',int,'this is test'],
      ['-u','--url',str,'this is url'],
      ['-c','--charset_out',str,'this is charset_out'],
      ['-f','--charset_in',str,'this is charset_in']
    ]
    cmd_param = get_cmd_param(param)

    print cmd_param

    step = cmd_param['step']
    test = cmd_param['test']
    _url  = cmd_param['url']
    charset_out  = cmd_param['charset_out']
    charset_in  = cmd_param['charset_in']
    if not charset_out:charset_out = 'utf-8'
    if not charset_in:charset_in = 'utf-8'

    config = get_config('./conf.ini')
    print config
    db_name = config['db']['name']
    # 连接数据库
    conn = sqlite.connect(os.path.abspath(db_name))
    if step == 1:
        #创建数据库
        print 'step 1 - start'
        create_acticle_db(conn)
        print 'step 1 - ok'
    elif step == 2:
        #初始化 文章地址列表
        print 'step 2 - start'
        with open(os.path.abspath('urls.txt')) as f:
             acticle_urls = f.read()
        acticle_urls_list =  acticle_urls.split('\n')
        print acticle_urls_list
        print len(acticle_urls_list)
        init_acticle_url(conn,acticle_urls_list)
        print 'step 2 - ok'
    elif step == 3:
        if test == 1:
            print _url
            html_content = http_get(_url)
            html_content = html_content.decode(charset_in,'ignore')
            html_content = lxml.html.fromstring(html_content)
            tag_a_content = html_content.cssselect(config['url']['a'])
            target_urls = []
            for tag_a in tag_a_content:
                tag_a_href = tag_a.get("href")
                detail_url = ''
                if tag_a_href.find('http://') > -1:
                    detail_url = tag_a_href
                else:
                    detail_url = config['global']['domain'] + tag_a_href
                if 'in' in config['url'].keys():
                    if detail_url.find(config['url']['in'])>-1:
                        target_urls.append(detail_url)
                    pass
                else:
                    target_urls.append(detail_url)
                pass
            target_urls = set(target_urls)
            for x in target_urls:
                print x
                pass

            pass
    elif step == 4:
        if test==1:
            print _url
            html_content = http_get(_url)
            html_content = html_content.decode(charset_in,'ignore')
            html_content = lxml.html.fromstring(html_content)
            for field in config['field']:
                if field.find('_index') > -1:continue
                try:
                    tag_content_list = html_content.cssselect(config['field'][field])
                    if len(tag_content_list)>0:
                        if field+'_index' in config['field'].keys():
                            if int(config['field'][field+'_index']) <= len(tag_content_list) :
                                tag_content = tag_content_list[int(config['field'][field+'_index'])]
                            else:
                                continue
                        else:
                            tag_content = tag_content_list[0]
                        tag_html_contnet = lxml.html.tostring(tag_content)
                        print HTMLParser.HTMLParser().unescape(tag_html_contnet).encode(charset_out,'ignore')
                        # print tag_content.text_content().encode('utf-8','ignore')
                    pass
                except Exception, e:
                    raise
                else:
                    pass
                finally:
                    pass
                
            pass
    elif step == 5:
        #开始
        article_urls = get_acticle_url(conn)
        for _url in article_urls:
            print 'urls: '+_url
            html_content = http_get(_url)
            html_content = html_content.decode(charset_in,'ignore')
            html_content = lxml.html.fromstring(html_content)
            tag_a_content = html_content.cssselect(config['url']['a'])
            target_urls = []
            for tag_a in tag_a_content:
                tag_a_href = tag_a.get("href")
                detail_url = ''
                if tag_a_href.find('http://') > -1:
                    detail_url = tag_a_href
                else:
                    detail_url = config['global']['domain'] + tag_a_href
                if 'in' in config['url'].keys():
                    if detail_url.find(config['url']['in'])>-1:
                        target_urls.append(detail_url)
                    pass
                else:
                    target_urls.append(detail_url)
                pass
            time.sleep(1)
            target_urls = set(target_urls)
            for x_detail_url in target_urls:
                print 'url: '+x_detail_url
                acticle_html_content = http_get(x_detail_url)
                acticle_html_content = acticle_html_content.decode(charset_in,'ignore')
                acticle_html_content = lxml.html.fromstring(acticle_html_content)
                sql_data = {'url':x_detail_url,'category_url':_url} 
                for field in config['field']:
                    if field.find('_index') > -1:continue
                    try:
                        tag_content_list = acticle_html_content.cssselect(config['field'][field])
                        if len(tag_content_list)>0:
                            if field+'_index' in config['field'].keys():
                                if int(config['field'][field+'_index']) <= len(tag_content_list) :
                                    tag_content = tag_content_list[int(config['field'][field+'_index'])]
                                else:
                                    continue
                            else:
                                tag_content = tag_content_list[0]
                            tag_html_contnet = lxml.html.tostring(tag_content)
                            field_value = HTMLParser.HTMLParser().unescape(tag_html_contnet)
                            print field_value.encode(charset_out,'ignore')
                            # print tag_content.text_content().encode('utf-8','ignore')
                            sql_data[field] = field_value
                        pass
                    except Exception, e:
                        raise
                    else:
                        pass
                    finally:
                        pass
                add_acticle(conn,sql_data)
                time.sleep(2)
                pass
            pass
    pass

conf.ini

[global]

domain = http://so.gushiwen.org

[db]
name = acticle.db

[url]
a = div.sons > p > a
in = /view

[field]

title = div.cont > h1 
content = div.cont > div.contson
other_1 = div.cont > p.source
other_2 = div.contyishang
other_2_index = 1
other_3 = div.contyishang
other_3_index = 3
other_4 = div.contyishang
other_4_index = 5

sql.py
#-*-coding:utf-8-*-

try :
    import sqlite3 as sqlite
except ImportError:
    from pysqlite2 import dbapi2 as sqlite

from lib import *

# 创建数据库
def create_acticle_db(conn):
    c = conn.cursor()
    # 文章
    c.execute('''DROP TABLE IF EXISTS "acticle";''')
    c.execute('''
        CREATE TABLE "acticle" (
            "id"  INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,
            "category_url" TEXT,
            "url"  TEXT,
            "title"  TEXT,
            "content"  TEXT,
            "other_1"  TEXT,
            "other_2"  TEXT,
            "other_3"  TEXT,
            "other_4"  TEXT,
            "other_5"  TEXT,
            "other_6"  TEXT,
            "other_7"  TEXT,
            "other_8"  TEXT,
            "other_9"  TEXT,
            "other_10"  TEXT,
            "status"  INTEGER,
            "add_time" TEXT,
            "send_time"  TEXT
        );
    ''')
    # 文章链接的列表
    c.execute('''DROP TABLE IF EXISTS "acticle_url";''')
    c.execute('''
        CREATE TABLE "acticle_url" (
            "id"  INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,
            "url"  TEXT,
            "status"  INTEGER,
            "add_time" TEXT
        );
    ''')
    #提交
    conn.commit()
    c.close()

#执行sql
def execute(conn,sql,data=[]):
	if sql is not None and sql != '':
		c = conn.cursor()
		c.execute(sql,data)
		conn.commit()
		c.close()

#查询
def query(conn,sql=None,data=None):
	if not data:data = []
	out = None
	if sql and sql != '':
		c = conn.cursor()
		c.execute(sql,data)
		record = c.fetchall()
		field = [i[0] for i in c.description]
		out = [dict(zip(field,i)) for i in record]
	return out

#初始化 acticle_url
def init_acticle_url(conn,urls=None):
	c = conn.cursor()
	for url in urls:
		if not url : continue
		sql = 'INSERT INTO acticle_url (url,status,add_time)values (?, ?, ?)'
		add_time = time2str()
		data = [url, 1,add_time]
		c.execute(sql,data)
		conn.commit()
		pass
	c.close()

#文章列表数据
def get_acticle_url(conn):
	sql = "SELECT * FROM acticle_url"
	res = query(conn,sql)
	out = []
	for x in res:
		out.append(x['url'])
		pass
	return out

#添加
def add_acticle(conn,data):
	fields = []
	fields_data = []
	fields_data_pos = [] 
	for field in data:
		fields.append(field)
		fields_data.append(data[field])
		fields_data_pos.append('?')
		pass
	sql = 'INSERT INTO acticle ('+','.join(fields)+') values ('+','.join(fields_data_pos)+') '
	execute(conn,sql,fields_data)
	pass
